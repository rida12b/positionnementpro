from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List
import json
import os
from openai import OpenAI
from dotenv import load_dotenv

# Chargement des variables d'environnement
load_dotenv()

app = FastAPI()

# Configuration CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configuration OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Mod√®les de donn√©es
class UserResponse(BaseModel):
    question_id: int
    answer: str

# Questions g√©n√©riques initiales
GENERIC_QUESTIONS = {
    1: {
        "id": 1,
        "text": "Dans quel type d'activit√© te sens-tu le plus √† l'aise ?",
        "options": [
            {"id": "creative", "text": "Les activit√©s cr√©atives et artistiques"},
            {"id": "technical", "text": "Les activit√©s techniques et logiques"},
            {"id": "social", "text": "Les activit√©s sociales et relationnelles"},
            {"id": "practical", "text": "Les activit√©s pratiques et concr√®tes"}
        ]
    },
    2: {
        "id": 2,
        "text": "Qu'est-ce qui te motive le plus dans un projet ?",
        "options": [
            {"id": "impact", "text": "Avoir un impact positif sur les autres"},
            {"id": "challenge", "text": "Relever des d√©fis et progresser"},
            {"id": "freedom", "text": "Avoir de la libert√© et de l'autonomie"},
            {"id": "create", "text": "Cr√©er et innover"}
        ]
    },
    3: {
        "id": 3,
        "text": "Comment pr√©f√®res-tu travailler ?",
        "options": [
            {"id": "team", "text": "En √©quipe, avec beaucoup d'interactions"},
            {"id": "solo", "text": "Seul(e), de mani√®re autonome"},
            {"id": "mix", "text": "Un m√©lange des deux selon les situations"},
            {"id": "lead", "text": "En guidant et en dirigeant les autres"}
        ]
    },
    4: {
        "id": 4,
        "text": "Quel environnement te correspond le mieux ?",
        "options": [
            {"id": "dynamic", "text": "Un environnement dynamique et changeant"},
            {"id": "stable", "text": "Un cadre stable et bien structur√©"},
            {"id": "flexible", "text": "Un environnement flexible et adaptable"},
            {"id": "outdoor", "text": "Un environnement vari√©, pas toujours au bureau"}
        ]
    },
    5: {
        "id": 5,
        "text": "Qu'est-ce qui compte le plus pour toi ?",
        "options": [
            {"id": "growth", "text": "L'apprentissage et le d√©veloppement personnel"},
            {"id": "balance", "text": "L'√©quilibre vie pro/perso"},
            {"id": "purpose", "text": "Le sens et l'utilit√© de mon travail"},
            {"id": "success", "text": "La r√©ussite et la reconnaissance"}
        ]
    }
}

@app.get("/")
async def read_root():
    return {"message": "Bienvenue sur l'API du Conseiller d'Orientation!"}

@app.get("/questions/{question_id}")
async def get_question(question_id: int):
    return GENERIC_QUESTIONS.get(question_id, {"error": "Question non trouv√©e"})

@app.post("/generate_questions")
async def generate_questions(responses: List[UserResponse]):
    try:
        formatted_responses = [
            {
                "question": GENERIC_QUESTIONS[r.question_id]["text"] if r.question_id <= 5 else "Question personnalis√©e",
                "r√©ponse": next(
                    (opt["text"] for opt in GENERIC_QUESTIONS[r.question_id]["options"] if opt["id"] == r.answer),
                    "Autre r√©ponse" if r.answer == "autre" else r.answer
                ) if r.question_id <= 5 else r.answer
            }
            for r in responses
        ]
        
        # D√©terminer le cycle actuel
        cycle = (len(formatted_responses) // 5) + 1
        
        prompt = f"""En tant que conseiller d'orientation expert, analyse ces r√©ponses et g√©n√®re 5 nouvelles questions g√©n√©rales et inclusives pour le cycle {cycle}/3.

R√©ponses pr√©c√©dentes du candidat :
{json.dumps(formatted_responses, indent=2, ensure_ascii=False)}

Pour le cycle {cycle}, g√©n√®re 5 questions qui explorent :

Cycle {cycle} - Th√®mes √† explorer :
{"- Les centres d'int√©r√™t g√©n√©raux\\n- Le style de vie souhait√©\\n- Les valeurs personnelles\\n- Les pr√©f√©rences de travail\\n- Les sources d'√©nergie" if cycle == 1 else "- Les objectifs de vie\\n- Les talents naturels\\n- Les r√™ves professionnels\\n- Le type d'impact d√©sir√©\\n- L'environnement id√©al" if cycle == 2 else "- Les aspirations profondes\\n- Les besoins essentiels\\n- Les motivations intrins√®ques\\n- Les conditions de r√©ussite\\n- Les priorit√©s de vie"}

Format JSON attendu :
[
    {{
        "id": {6 + (cycle-1)*5},
        "text": "Question g√©n√©rale et inclusive",
        "options": [
            {{"id": "option1", "text": "Premi√®re option g√©n√©rale"}},
            {{"id": "option2", "text": "Deuxi√®me option g√©n√©rale"}},
            {{"id": "option3", "text": "Troisi√®me option g√©n√©rale"}},
            {{"id": "option4", "text": "Quatri√®me option g√©n√©rale"}}
        ]
    }},
    // ... r√©p√©ter pour les 4 autres questions
]

IMPORTANT : 
- Les questions doivent √™tre g√©n√©rales et s'appliquer √† tout type de profil
- √âvite les questions trop sp√©cifiques ou techniques
- Propose des options larges et inclusives
- Chaque option doit √™tre simple et claire
- Les questions doivent permettre de mieux comprendre la personne sans la mettre dans une case"""

        print(f"G√©n√©ration des questions pour le cycle {cycle}")

        completion = client.chat.completions.create(
            model="gpt-4-0125-preview",
            messages=[
                {"role": "system", "content": f"Tu es un conseiller d'orientation expert qui g√©n√®re des questions g√©n√©rales et inclusives. Adapte tes questions pour qu'elles conviennent √† tout type de profil. √âvite les questions trop sp√©cifiques ou techniques."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        
        response_content = completion.choices[0].message.content
        print("R√©ponse de GPT:", response_content)

        # Nettoyage et validation comme avant...
        response_content = response_content.strip()
        if response_content.startswith("```json"):
            response_content = response_content[7:]
        if response_content.endswith("```"):
            response_content = response_content[:-3]
        response_content = response_content.strip()

        questions = json.loads(response_content)
        
        # Validation
        if not isinstance(questions, list) or len(questions) != 5:
            raise ValueError("La r√©ponse doit contenir exactement 5 questions")
            
        for q in questions:
            if not all(key in q for key in ["id", "text", "options"]):
                raise ValueError("Format de question invalide")
            if not isinstance(q["options"], list) or len(q["options"]) != 4:
                raise ValueError("Chaque question doit avoir exactement 4 options")

        return {"questions": questions}
        
    except json.JSONDecodeError as e:
        print("Erreur de d√©codage JSON:", str(e))
        print("Contenu re√ßu:", response_content)
        raise HTTPException(status_code=500, detail="Erreur de format dans la r√©ponse de l'IA")
    except Exception as e:
        print("Erreur lors de la g√©n√©ration des questions:", str(e))
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/recommend")
async def get_recommendations(responses: List[UserResponse]):
    try:
        formatted_responses = [
            {
                "question": GENERIC_QUESTIONS[r.question_id]["text"] if r.question_id <= 5 else "Question personnalis√©e",
                "r√©ponse": next(
                    (opt["text"] for opt in GENERIC_QUESTIONS[r.question_id]["options"] if opt["id"] == r.answer),
                    r.answer
                ) if r.question_id <= 5 else r.answer
            }
            for r in responses
        ]
        
        prompt = f"""En tant que conseiller d'orientation professionnel, analyse ces r√©ponses et recommande 3 m√©tiers parfaitement adapt√©s au profil.

R√©ponses du candidat :
{json.dumps(formatted_responses, indent=2, ensure_ascii=False)}

IMPORTANT :
- Ne te base pas sur les dipl√¥mes ou l'exp√©rience
- Concentre-toi sur la personnalit√©, les talents naturels et les aspirations
- Propose des m√©tiers innovants et motivants
- Explique pourquoi chaque m√©tier correspond parfaitement

Format de r√©ponse :
1. Analyse du profil (3-4 phrases percutantes sur les points forts)

2. Pour chaque m√©tier :
   üéØ [Nom du m√©tier]
   üìù Description inspirante
   ‚ú® Pourquoi ce m√©tier est fait pour toi
   üîë Comp√©tences cl√©s √† d√©velopper
   üìö Parcours possibles pour y arriver"""

        completion = client.chat.completions.create(
            model="gpt-4-0125-preview",
            messages=[
                {"role": "system", "content": "Tu es un conseiller d'orientation visionnaire qui r√©v√®le le potentiel des gens et leur sugg√®re des m√©tiers passionnants. Sois inspirant et motivant dans tes recommandations."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        
        return {"recommendations": completion.choices[0].message.content}
    except Exception as e:
        print("Erreur lors de la g√©n√©ration des recommandations:", str(e))
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000) 